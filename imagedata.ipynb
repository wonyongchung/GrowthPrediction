{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Failed to start the Kernel 'wonyong (Python 3.8.8)'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. listen EFAULT: bad address in system call argument 127.0.0.1:9001"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(data_dir):\n",
    "    img_path_list = []\n",
    "    label_list = []\n",
    "    for case_name in os.listdir(data_dir):\n",
    "        current_path = os.path.join(data_dir, case_name)\n",
    "        if os.path.isdir(current_path):\n",
    "            # get image path\n",
    "            img_path_list.extend(glob(os.path.join(current_path, 'image', '*.jpg')))\n",
    "            img_path_list.extend(glob(os.path.join(current_path, 'image', '*.png')))\n",
    "            \n",
    "            # get label\n",
    "            label_df = pd.read_csv(current_path+'/label.csv')\n",
    "            label_list.extend(label_df['leaf_weight'])\n",
    "                \n",
    "    return img_path_list, label_list\n",
    "\n",
    "def get_test_data(data_dir):\n",
    "    # get image path\n",
    "    img_path_list = glob(os.path.join(data_dir, 'image', '*.jpg'))\n",
    "    img_path_list.extend(glob(os.path.join(data_dir, 'image', '*.png')))\n",
    "    img_path_list.sort(key=lambda x:int(x.split('\\\\')[-1].split('.')[0]))\n",
    "    return img_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = glob.glob(os.path.join('.', 'dataset_128', 'train', 'CASE*', 'image', '*'))\n",
    "traintensor = torch.Tensor(size=[0,3,128,128])\n",
    "for index, i in enumerate(trainpath):\n",
    "    img = Image.open(i)\n",
    "    transform = transforms.ToTensor()\n",
    "    temp = transform(img)\n",
    "    temp = temp.unsqueeze(dim=0)\n",
    "    # traintensor.cat(temp)\n",
    "    traintensor = torch.cat([traintensor, temp],dim = 0)\n",
    "    if index%100==0:\n",
    "        print(1)\n",
    "traintensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentation import *\n",
    "import random\n",
    "import time\n",
    "def augment(traintensor):\n",
    "    augmenttraintensor = torch.Tensor(size = [0,3,128,128])\n",
    "    for index, image in enumerate(traintensor):\n",
    "        start = time.time()\n",
    "        rand = random.random()\n",
    "        #image = image.unsqueeze(dim = 0)\n",
    "        #print(image.shape)\n",
    "        if rand<0.33:\n",
    "            temp_1 = iso_scaling(image)\n",
    "            temp_2 = gau_blur(image)\n",
    "            temp_1 = temp_1.unsqueeze(dim = 0)\n",
    "            temp_2 = temp_2.unsqueeze(dim = 0)\n",
    "        elif rand<0.67 and rand>=0.33:\n",
    "            temp_1 = rand_erasing(image)\n",
    "            temp_2 = gau_noise(image)\n",
    "            temp_1 = temp_1.unsqueeze(dim = 0)\n",
    "            temp_2 = temp_2.unsqueeze(dim = 0)\n",
    "        else:\n",
    "            temp_1 = salt_pepper(image)\n",
    "            temp_2 = hue_rotation(image)\n",
    "            temp_1 = temp_1.unsqueeze(dim = 0)\n",
    "            temp_2 = temp_2.unsqueeze(dim = 0)\n",
    "        image = image.unsqueeze(dim = 0)\n",
    "        augmenttraintensor = torch.cat([augmenttraintensor, temp_1],dim=0)\n",
    "        augmenttraintensor = torch.cat([augmenttraintensor, temp_2],dim=0)\n",
    "        augmenttraintensor = torch.cat([augmenttraintensor, image],dim=0)\n",
    "        if index%100==0:\n",
    "            print(\"------\", index)\n",
    "            print(time.time() - start)\n",
    "    return augmenttraintensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintensor1 = traintensor[:400]\n",
    "traintensor2 = traintensor[400:800]\n",
    "traintensor3 = traintensor[800:1200]\n",
    "traintensor4 = traintensor[1200:]\n",
    "traintensor_all = torch.Tensor(size = [0,3,128,128])\n",
    "traintensor_all = torch.cat([traintensor_all, augment(traintensor1)], dim = 0)\n",
    "print(\"&&&&&\")\n",
    "traintensor_all = torch.cat([traintensor_all, augment(traintensor2)], dim = 0)\n",
    "print(\"&&&&&\")\n",
    "traintensor_all = torch.cat([traintensor_all, augment(traintensor3)], dim = 0)\n",
    "print(\"&&&&&\")\n",
    "traintensor_all = torch.cat([traintensor_all, augment(traintensor4)], dim = 0)\n",
    "print(traintensor_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_path, all_label = get_train_data('./dataset/train')\n",
    "test_img_path = get_test_data('./dataset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train : Validation = 0.8 : 0.2 Split\n",
    "train_len = int(len(all_img_path)*0.8)\n",
    "\n",
    "train_img_path = all_img_path[:train_len]\n",
    "train_label = all_label[:train_len]\n",
    "\n",
    "vali_img_path = all_img_path[train_len:]\n",
    "vali_label = all_label[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_label)+len(vali_label)\n",
    "train_all_label_1 = train_label+vali_label\n",
    "train_all_label = []\n",
    "for i in train_all_label_1:\n",
    "    train_all_label.append(i)\n",
    "    train_all_label.append(i)\n",
    "    train_all_label.append(i)\n",
    "len(train_all_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimage_tensor = traintensor_all[:1250]\n",
    "trainlabel = train_all_label[:1250]\n",
    "validimage_tensor = traintensor_all[1250:]\n",
    "validlabel = train_all_label[1250:]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a51ec424ca3fef9d1a84032e6834f011e9490d4e43fd40a1b36ea386415549a3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('wonyong')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
